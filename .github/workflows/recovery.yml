name: RECOVERY

on:
  workflow_dispatch:
    inputs:
      RECOVERY_URL:
        description: 'URL to base recovery (supports .img, .img.lz4, .img.tar, .tar.md5, Dropbox/Drive/TWRP)'
        required: true
        default: 'https://dl.twrp.me/beyondx/twrp-3.7.0_9-1-beyondx.img.tar.html'

      PARTITION_SIZE:
        description: 'Recovery partition size in bytes (beyondx = 67108864)'
        required: false
        default: '67108864'

env:
  # Used if a step needs an absolute workspace path
  WS: ${{ github.workspace }}

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python & tools
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install prerequisites
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y curl wget lz4 tar openssl file coreutils
          python -m pip install --upgrade pip
          pip install --no-cache-dir gdown

      - name: Ensure patch tools (magiskboot, avbtool, scripts, phh.pem)
        run: |
          set -euo pipefail
          base="https://raw.githubusercontent.com/Johx22/Patch-Recovery/master"  # upstream
          for f in magiskboot avbtool script1.sh script2.sh vbmeta_disabled_R.tar phh.pem; do
            if [ ! -e "$f" ]; then
              echo "Missing $f → fetching from upstream"
              curl -L --fail -o "$f" "$base/$f"
            fi
          done
          chmod +x magiskboot avbtool script1.sh script2.sh

      - name: Normalize & download URL (handles Dropbox/Drive/TWRP)
        id: fetch
        run: |
          set -euo pipefail
          url="${{ github.event.inputs.RECOVERY_URL }}"
          mkdir -p "$WS/_dl"
          echo "$url" > "$WS/_dl/input.url"

          # If user pasted a TWRP HTML page (…img.tar.html), switch to the actual file URL.
          if echo "$url" | grep -qiE '\.img(\.tar)?\.html$'; then
            # TWRP file pages contain a "Download ..." link to the real file; simple transform:
            url="$(echo "$url" | sed -E 's/\.html$//')"
          fi

          # Dropbox: rewrite to dl.dropboxusercontent.com and force dl=1; drop ephemeral "st=" if present.
          if echo "$url" | grep -qi 'dropbox.com'; then
            url="$(echo "$url" \
              | sed -E 's#://www.dropbox.com#://dl.dropboxusercontent.com#; s/[?&]dl=[01]//; s/[?&]st=[^&]+//')"
            case "$url" in *\?*) url="${url}&dl=1" ;; *) url="${url}?dl=1" ;; esac
          fi

          echo "$url" | tee "$WS/_dl/final.url"

          # Try Google Drive first (handles confirm/quota). Otherwise curl.
          if echo "$url" | grep -qiE 'drive\.google\.com|drive\.usercontent\.google\.com|/open\?id='; then
            gdown --fuzzy "$url" -O "$WS/_dl/input.bin"
          else
            curl -L --fail --retry 5 --retry-all-errors \
                 -H "User-Agent: CI-Downloader" \
                 -D "$WS/_dl/headers.txt" \
                 -o "$WS/_dl/input.bin" "$url"
          fi

          test -s "$WS/_dl/input.bin"
          file "$WS/_dl/input.bin" | tee "$WS/_dl/filetype.txt"
          if file "$WS/_dl/input.bin" | grep -qiE 'HTML|XML|ASCII text'; then
            echo "Downloaded HTML/text instead of a binary; the link is not a direct file or is expired."
            exit 86
          fi

          sha256sum "$WS/_dl/input.bin" | tee "$WS/_dl/input.sha256"

      - name: Turn whatever we got into recovery.img (untar / unlz4)
        run: |
          set -euo pipefail
          cd "$WS/_dl"

          # If it's a tar (TWRP .img.tar or .tar.md5), extract and pick an image
          if file input.bin | grep -qi 'tar archive'; then
            mkdir extracted && tar -xf input.bin -C extracted
            cand=""
            for n in recovery.img recovery*.img *.img *.img.lz4; do
              if [ -f "extracted/$n" ]; then cand="extracted/$n"; break; fi
            done
            if [ -z "$cand" ]; then
              echo "No .img or .img.lz4 found inside tar"
              exit 87
            fi
            mv "$cand" stage.img
          else
            mv input.bin stage.img
          fi

          # LZ4 → IMG
          if file stage.img | grep -qi 'LZ4'; then
            lz4 -d -f stage.img recovery.img
          else
            mv stage.img recovery.img
          fi
          test -s recovery.img
          file recovery.img | tee recovery.filetype.txt
          sha256sum recovery.img | tee recovery.sha256

      - name: Patch (script1/script2 + AVB footer) with hard size guard
        env:
          PARTITION_SIZE: ${{ github.event.inputs.PARTITION_SIZE }}
        run: |
          set -euo pipefail
          cd "$WS/_dl"
          cp -f ../magiskboot ../avbtool ../script1.sh ../script2.sh ../phh.pem .

          # Phase 1/2: keep your original scripts but don’t die if they no-op
          chmod +x script1.sh script2.sh magiskboot avbtool
          ./script1.sh || true
          ./script2.sh || true

          # AVB hash footer on the PATCHED image
          # (Use exact partition size for beyondx recovery: default 67108864)
          SIZE="${PARTITION_SIZE:-67108864}"
          echo "Using partition size: $SIZE bytes"
          python3 avbtool extract_public_key --key phh.pem --output phh.pub.bin || true
          python3 avbtool add_hash_footer \
            --partition_name recovery \
            --partition_size "$SIZE" \
            --image recovery-patched.img \
            --key phh.pem \
            --algorithm SHA256_RSA4096

          test -s recovery-patched.img
          # Guard: refuse to proceed if image > partition_size
          actual=$(wc -c < recovery-patched.img)
          if [ "$actual" -gt "$SIZE" ]; then
            echo "ERROR: patched image ($actual bytes) exceeds recovery partition ($SIZE bytes)."
            exit 88
          fi

          sha256sum recovery-patched.img | tee recovery-patched.sha256

      - name: Pack Odin tar.md5 + include vbmeta helper
        run: |
          set -euo pipefail
          cd "$WS/_dl"
          mkdir -p "$WS/output"
          cp recovery-patched.img "$WS/output/recovery.img"
          tar -C "$WS/output" -cvf "$WS/output/fastbootd-recovery.tar" recovery.img
          ( cd "$WS/output" && md5sum -t fastbootd-recovery.tar >> fastbootd-recovery.tar )
          mv "$WS/output/fastbootd-recovery.tar" "$WS/output/fastbootd-recovery.tar.md5"
          cp "$WS/vbmeta_disabled_R.tar" "$WS/output/" || true

          # Write summary
          {
            echo "### Artifacts"
            echo "- fastbootd-recovery.tar.md5 (flash in Odin AP)"
            echo "- vbmeta_disabled_R.tar (flash per guide)"
            echo
            echo "### Checksums"
            echo '```'
            sha256sum "$WS/output/fastbootd-recovery.tar.md5"
            sha256sum "$WS/output/recovery.img"
            echo '```'
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: Patched-Recovery
          path: |
            ${{ github.workspace }}/output/fastbootd-recovery.tar.md5
            ${{ github.workspace }}/output/vbmeta_disabled_R.tar
            ${{ github.workspace }}/_dl/*.sha256
            ${{ github.workspace }}/_dl/*.txt
            ${{ github.workspace }}/_dl/*.url

      # Always upload debug bundle (headers, filetypes, etc.)
      - name: Upload debug bundle
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: Debug-Download-Bundle
          path: |
            ${{ github.workspace }}/_dl/**
